#!/usr/bin/env python3
"""
St. Edward Calendar Sync - Complete Production Version
"""
import os
import logging
import secrets
import traceback
import signal
import sys
import config  # <-- ADDED THIS IMPORT
from datetime import datetime
from flask import Flask, render_template, jsonify, redirect, session, request

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Flask
app = Flask(__name__)
app.secret_key = secrets.token_hex(32)

# Global components - will be initialized after first successful load
sync_engine = None
scheduler = None
auth_manager = None

def initialize_components():
    """Initialize sync components safely"""
    global sync_engine, scheduler, auth_manager
    
    if auth_manager is None:
        try:
            from auth.microsoft_auth import MicrosoftAuth
            auth_manager = MicrosoftAuth()
            logger.info("‚úÖ Auth manager initialized")
        except Exception as e:
            logger.error(f"Failed to initialize auth manager: {e}")
            return False
    
    if sync_engine is None:
        try:
            from sync.engine import SyncEngine
            sync_engine = SyncEngine(auth_manager)
            logger.info("‚úÖ Sync engine initialized")
        except Exception as e:
            logger.error(f"Failed to initialize sync engine: {e}")
            # Continue without sync engine for now
    
    if scheduler is None:
        try:
            from sync.scheduler import SyncScheduler
            scheduler = SyncScheduler(sync_engine)
            scheduler.start()
            logger.info("‚úÖ Scheduler started")
        except Exception as e:
            logger.error(f"Failed to initialize scheduler: {e}")
            # Continue without scheduler for now
    
    return True

@app.route('/health')
def health_check():
    """Health check for Render"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "st-edward-calendar-sync"
    }), 200

@app.route('/health/detailed')
def detailed_health():
    """Detailed health check"""
    checks = {}
    
    # Check authentication
    if auth_manager:
        checks['authenticated'] = auth_manager.is_authenticated()
    else:
        checks['authenticated'] = False
    
    # Check sync engine
    checks['sync_engine_loaded'] = sync_engine is not None
    
    # Check scheduler
    if scheduler:
        checks['scheduler_running'] = scheduler.is_running()
    else:
        checks['scheduler_running'] = False
    
    status = "healthy" if all(checks.values()) else "degraded"
    
    return jsonify({
        "status": status,
        "timestamp": datetime.now().isoformat(),
        "checks": checks
    })

@app.route('/status')
def get_status():
    """Get current system status"""
    try:
        if not auth_manager:
            initialize_components()
        
        status = {
            "authenticated": auth_manager.is_authenticated() if auth_manager else False,
            "sync_in_progress": False,
            "last_sync_time": None,
            "last_sync_result": {"success": False, "message": "Not synced yet"},
            "scheduler_running": scheduler.is_running() if scheduler else False,
            "dry_run_mode": getattr(config, 'DRY_RUN_MODE', False),
            "circuit_breaker_state": "closed",
            "rate_limit_remaining": 20,
            "total_syncs": 0
        }
        
        if sync_engine:
            engine_status = sync_engine.get_status()
            status.update(engine_status)
        
        return jsonify(status)
        
    except Exception as e:
        logger.error(f"Status check failed: {e}")
        return jsonify({
            "error": str(e),
            "authenticated": False,
            "sync_in_progress": False
        }), 500

@app.route('/')
def index():
    """Main dashboard"""
    try:
        # Initialize components if needed
        initialize_components()
        
        if not auth_manager or not auth_manager.is_authenticated():
            # Show auth page
            state = secrets.token_urlsafe(16)
            session['oauth_state'] = state
            auth_url = auth_manager.get_auth_url(state) if auth_manager else "#"
            
            return f'''
            <!DOCTYPE html>
            <html>
            <head>
                <title>St. Edward Calendar Sync</title>
                <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üìÖ</text></svg>">
            </head>
            <body style="font-family: Arial; text-align: center; margin-top: 100px; background: #f5f5f5;">
                <div style="background: white; max-width: 500px; margin: 0 auto; padding: 40px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                    <h1 style="color: #005921;">üóìÔ∏è St. Edward Calendar Sync</h1>
                    <p style="margin: 20px 0; color: #666;">Automated synchronization between internal and public calendars</p>
                    <a href="{auth_url}" style="background: #0078d4; color: white; padding: 15px 30px; text-decoration: none; border-radius: 5px; font-size: 18px; display: inline-block;">
                        Sign in with Microsoft
                    </a>
                    <p style="margin-top: 30px; font-size: 12px; color: #999;">
                        St. Edward Church & School
                    </p>
                </div>
            </body>
            </html>
            '''
        
        # User is authenticated - show dashboard
        last_sync_time = None
        if sync_engine:
            status = sync_engine.get_status()
            last_sync_time = status.get('last_sync_time')
        
        return render_template('index.html', 
                             last_sync_time=last_sync_time,
                             authenticated=True)
        
    except Exception as e:
        logger.error(f"Index route error: {e}")
        return f'''
        <html><body style="font-family: Arial; text-align: center; margin-top: 100px;">
            <h1>‚ö†Ô∏è Error</h1>
            <p>System error: {str(e)}</p>
            <p>The service is starting up. Please refresh in a moment.</p>
        </body></html>
        ''', 500

@app.route('/sync', methods=['POST'])
def trigger_sync():
    """Trigger manual sync"""
    try:
        if not sync_engine:
            return jsonify({"error": "Sync engine not initialized"}), 500
        
        if not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated", "redirect": "/"}), 401
        
        result = sync_engine.sync_calendars()
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Sync trigger error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/auth/callback')
def auth_callback():
    """OAuth callback"""
    try:
        if not auth_manager:
            initialize_components()
        
        code = request.args.get('code')
        state = request.args.get('state')
        
        if not code or not state or state != session.get('oauth_state'):
            return "Authentication failed: Invalid request", 400
        
        if auth_manager and auth_manager.exchange_code_for_token(code):
            return redirect('/')
        else:
            return "Authentication failed: Could not exchange token", 400
            
    except Exception as e:
        logger.error(f"Auth callback error: {e}")
        return f"Authentication error: {e}", 500

@app.route('/logout')
def logout():
    """Clear session and tokens"""
    try:
        session.clear()
        if auth_manager:
            auth_manager.clear_tokens()
        return redirect('/')
    except Exception as e:
        logger.error(f"Logout error: {e}")
        return redirect('/')

@app.route('/debug')
def debug_info():
    """Debug information"""
    try:
        debug_data = {
            "timestamp": datetime.now().isoformat(),
            "environment_vars": {
                "CLIENT_ID": bool(os.environ.get('CLIENT_ID')),
                "CLIENT_SECRET": bool(os.environ.get('CLIENT_SECRET')),
                "TENANT_ID": bool(os.environ.get('TENANT_ID')),
                "ACCESS_TOKEN": bool(os.environ.get('ACCESS_TOKEN')),
                "REFRESH_TOKEN": bool(os.environ.get('REFRESH_TOKEN')),
            },
            "config_loaded": True,
            "components": {
                "auth_manager": auth_manager is not None,
                "sync_engine": sync_engine is not None,
                "scheduler": scheduler is not None,
                "scheduler_running": scheduler.is_running() if scheduler else False
            }
        }
        
        if auth_manager:
            debug_data["authenticated"] = auth_manager.is_authenticated()
        
        return jsonify(debug_data)
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/signatures')
def debug_signatures():
    """Debug endpoint to analyze event signatures"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated or sync engine not available"}), 401
        
        # Get calendar IDs
        source_id = sync_engine.reader.find_calendar_id(config.SOURCE_CALENDAR)
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        
        if not source_id or not target_id:
            return jsonify({"error": "Could not find required calendars"}), 404
        
        # Get events
        source_events = sync_engine.reader.get_public_events(source_id)
        target_events = sync_engine.reader.get_calendar_events(target_id)
        
        if not source_events or not target_events:
            return jsonify({"error": "Could not retrieve calendar events"}), 500
        
        # Analyze signatures
        analysis = {
            "source_events": len(source_events),
            "target_events": len(target_events),
            "source_signatures": {},
            "target_signatures": {},
            "signature_analysis": {
                "source_duplicates": [],
                "target_duplicates": [],
                "missing_in_target": [],
                "extra_in_target": [],
                "signature_collisions": []
            }
        }
        
        # Analyze source events
        source_sig_count = {}
        for event in source_events:
            sig = sync_engine._create_event_signature(event)
            if sig.startswith("skip:"):
                continue
                
            analysis["source_signatures"][sig] = {
                "subject": event.get('subject'),
                "start": event.get('start', {}).get('dateTime'),
                "type": event.get('type'),
                "id": event.get('id')
            }
            
            source_sig_count[sig] = source_sig_count.get(sig, 0) + 1
            if source_sig_count[sig] > 1:
                analysis["signature_analysis"]["source_duplicates"].append({
                    "signature": sig,
                    "count": source_sig_count[sig],
                    "subject": event.get('subject')
                })
        
        # Analyze target events
        target_sig_count = {}
        for event in target_events:
            sig = sync_engine._create_event_signature(event)
            if sig.startswith("skip:"):
                continue
                
            analysis["target_signatures"][sig] = {
                "subject": event.get('subject'),
                "start": event.get('start', {}).get('dateTime'),
                "type": event.get('type'),
                "id": event.get('id')
            }
            
            target_sig_count[sig] = target_sig_count.get(sig, 0) + 1
            if target_sig_count[sig] > 1:
                analysis["signature_analysis"]["target_duplicates"].append({
                    "signature": sig,
                    "count": target_sig_count[sig],
                    "subject": event.get('subject')
                })
        
        # Find missing and extra events
        source_sigs = set(analysis["source_signatures"].keys())
        target_sigs = set(analysis["target_signatures"].keys())
        
        missing_sigs = source_sigs - target_sigs
        extra_sigs = target_sigs - source_sigs
        
        for sig in missing_sigs:
            analysis["signature_analysis"]["missing_in_target"].append({
                "signature": sig,
                "subject": analysis["source_signatures"][sig]["subject"]
            })
        
        for sig in extra_sigs:
            analysis["signature_analysis"]["extra_in_target"].append({
                "signature": sig,
                "subject": analysis["target_signatures"][sig]["subject"]
            })
        
        # Check for signature collisions (same signature, different events)
        for sig in source_sigs & target_sigs:
            source_event = analysis["source_signatures"][sig]
            target_event = analysis["target_signatures"][sig]
            
            if (source_event["subject"] != target_event["subject"] or 
                source_event["start"] != target_event["start"]):
                analysis["signature_analysis"]["signature_collisions"].append({
                    "signature": sig,
                    "source": source_event,
                    "target": target_event
                })
        
        return jsonify(analysis)
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/duplicates')
def debug_duplicates():
    """Find and analyze duplicate events in target calendar"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group events by subject and start time
        duplicates = {}
        subject_groups = {}
        
        for event in target_events:
            subject = event.get('subject', '').lower().strip()
            start = event.get('start', {}).get('dateTime', '')
            
            # Group by subject
            if subject not in subject_groups:
                subject_groups[subject] = []
            subject_groups[subject].append({
                'id': event.get('id'),
                'subject': event.get('subject'),
                'start': start,
                'created': event.get('createdDateTime'),
                'modified': event.get('lastModifiedDateTime'),
                'signature': sync_engine._create_event_signature(event)
            })
        
        # Find duplicates
        for subject, events in subject_groups.items():
            if len(events) > 1:
                # Group by start time within same subject
                time_groups = {}
                for event in events:
                    start_key = event['start'][:16] if event['start'] else 'no-time'  # Group by date+hour+minute
                    if start_key not in time_groups:
                        time_groups[start_key] = []
                    time_groups[start_key].append(event)
                
                # Find time groups with multiple events
                for start_time, time_events in time_groups.items():
                    if len(time_events) > 1:
                        duplicates[f"{subject}_{start_time}"] = {
                            'subject': subject,
                            'start_time': start_time,
                            'count': len(time_events),
                            'events': time_events
                        }
        
        return jsonify({
            "total_events": len(target_events),
            "duplicate_groups": len(duplicates),
            "duplicates": duplicates,
            "summary": {
                "total_duplicate_events": sum(dup['count'] for dup in duplicates.values()),
                "subjects_with_duplicates": list(duplicates.keys())
            }
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/clean-duplicates', methods=['POST'])
def clean_duplicates():
    """Remove duplicate events from target calendar"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        # Get target calendar
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group events by signature
        signature_groups = {}
        for event in target_events:
            sig = sync_engine._create_event_signature(event)
            if sig.startswith("skip:"):
                continue
                
            if sig not in signature_groups:
                signature_groups[sig] = []
            signature_groups[sig].append(event)
        
        # Find duplicates and keep only the newest
        to_delete = []
        kept_count = 0
        
        for sig, events in signature_groups.items():
            if len(events) > 1:
                # Sort by creation time, keep the newest
                events.sort(key=lambda x: x.get('createdDateTime', ''), reverse=True)
                kept_event = events[0]
                duplicates = events[1:]
                
                kept_count += 1
                to_delete.extend(duplicates)
                
                logger.info(f"Found {len(duplicates)} duplicates for '{kept_event.get('subject')}', keeping newest")
        
        # Delete duplicates
        deleted_count = 0
        failed_deletes = []
        
        for event in to_delete:
            event_id = event.get('id')
            if sync_engine.writer.delete_event(target_id, event_id):
                deleted_count += 1
                logger.info(f"Deleted duplicate: {event.get('subject')} (ID: {event_id[:8]}...)")
            else:
                failed_deletes.append(event_id)
                logger.error(f"Failed to delete: {event.get('subject')} (ID: {event_id[:8]}...)")
        
        return jsonify({
            "success": True,
            "total_events_found": len(target_events),
            "duplicate_groups": len([g for g in signature_groups.values() if len(g) > 1]),
            "duplicates_found": len(to_delete),
            "duplicates_deleted": deleted_count,
            "failed_deletes": len(failed_deletes),
            "events_kept": kept_count + len([g for g in signature_groups.values() if len(g) == 1]),
            "failed_delete_ids": failed_deletes
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/dry-run/enable')
def enable_dry_run():
    """Enable dry run mode"""
    config.DRY_RUN_MODE = True
    return jsonify({"message": "Dry run mode enabled", "dry_run": True})

@app.route('/dry-run/disable') 
def disable_dry_run():
    """Disable dry run mode"""
    config.DRY_RUN_MODE = False
    return jsonify({"message": "Dry run mode disabled", "dry_run": False})

@app.route('/debug/status')
def debug_status():
    """Debug the current state and show what's wrong"""
    return '''
    <html><body style="font-family: Arial; padding: 20px;">
        <h1>üîß Debug Status & Cleanup</h1>
        
        <button onclick="checkStatus()" style="background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; margin: 5px;">
            Check Status
        </button>
        
        <button onclick="checkDuplicates()" style="background: #ffc107; color: black; padding: 10px 20px; border: none; border-radius: 5px; margin: 5px;">
            Check Duplicates
        </button>
        
        <button onclick="cleanDupes()" style="background: #dc3545; color: white; padding: 10px 20px; border: none; border-radius: 5px; margin: 5px;">
            Clean Duplicates
        </button>
        
        <div id="result" style="margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 5px; max-height: 400px; overflow-y: auto;"></div>
        
        <script>
        function log(message) {
            const result = document.getElementById('result');
            result.innerHTML += '<div style="margin: 5px 0; padding: 5px; background: white; border-left: 3px solid #007bff;">' + message + '</div>';
            result.scrollTop = result.scrollHeight;
        }
        
        async function checkStatus() {
            log('üîç Checking system status...');
            try {
                const response = await fetch('/status');
                const data = await response.json();
                log('<strong>‚úÖ Status Response:</strong><br><pre>' + JSON.stringify(data, null, 2) + '</pre>');
            } catch (error) {
                log('‚ùå Status Error: ' + error.message);
            }
        }
        
        async function checkDuplicates() {
            log('üîç Checking for duplicates...');
            try {
                const response = await fetch('/debug/duplicates');
                const data = await response.json();
                log('<strong>üìä Duplicates Found:</strong><br><pre>' + JSON.stringify(data, null, 2) + '</pre>');
            } catch (error) {
                log('‚ùå Duplicates Check Error: ' + error.message);
            }
        }
        
        async function cleanDupes() {
            log('üßπ Starting cleanup...');
            try {
                const response = await fetch('/debug/clean-duplicates', {method: 'POST'});
                const data = await response.json();
                
                log('<strong>üóëÔ∏è Cleanup Response:</strong><br><pre>' + JSON.stringify(data, null, 2) + '</pre>');
                
                if (data.success) {
                    log('<strong>‚úÖ Cleanup Summary:</strong>');
                    log('‚Ä¢ Total events: ' + (data.total_events_found || 'unknown'));
                    log('‚Ä¢ Duplicates deleted: ' + (data.duplicates_deleted || 'unknown'));
                    log('‚Ä¢ Events kept: ' + (data.events_kept || 'unknown'));
                    log('‚Ä¢ Failed deletes: ' + (data.failed_deletes || 'unknown'));
                } else {
                    log('<strong>‚ùå Cleanup failed:</strong> ' + (data.error || 'Unknown error'));
                }
            } catch (error) {
                log('‚ùå Cleanup Error: ' + error.message);
            }
        }
        
        // Clear log
        function clearLog() {
            document.getElementById('result').innerHTML = '';
        }
        </script>
        
        <br><button onclick="clearLog()" style="background: #6c757d; color: white; padding: 5px 15px; border: none; border-radius: 3px;">Clear Log</button>
    </body></html>
    '''

def signal_handler(sig, frame):
    """Handle shutdown signals"""
    logger.info("Received shutdown signal, cleaning up...")
    if scheduler:
        scheduler.stop()
    sys.exit(0)

# Register signal handlers
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# Initialize on startup
logger.info("üöÄ Starting St. Edward Calendar Sync")
initialize_components()

# Add this improved duplicate detector to your app.py

@app.route('/debug/precise-duplicates')
def precise_duplicates():
    """Find TRUE duplicates - identical events that shouldn't exist twice"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group events by EXACT match criteria for true duplicates
        exact_groups = {}
        
        for event in target_events:
            subject = event.get('subject', '').strip()
            start_datetime = event.get('start', {}).get('dateTime', '')
            end_datetime = event.get('end', {}).get('dateTime', '')
            is_all_day = event.get('isAllDay', False)
            event_type = event.get('type', 'singleInstance')
            
            # Skip recurring series masters and occurrences for now - focus on single events
            if event_type in ['seriesMaster', 'occurrence']:
                continue
                
            # Create precise matching key
            # For single events: subject + start + end + all-day flag
            key = f"{subject}|{start_datetime}|{end_datetime}|{is_all_day}"
            
            if key not in exact_groups:
                exact_groups[key] = []
            
            exact_groups[key].append({
                'id': event.get('id'),
                'subject': event.get('subject'),
                'start': start_datetime,
                'end': end_datetime,
                'isAllDay': is_all_day,
                'type': event_type,
                'created': event.get('createdDateTime'),
                'modified': event.get('lastModifiedDateTime'),
                'categories': event.get('categories', [])
            })
        
        # Find groups with multiple identical events
        true_duplicates = {}
        for key, events in exact_groups.items():
            if len(events) > 1:
                # Parse the key for display
                parts = key.split('|')
                subject = parts[0]
                start = parts[1]
                
                # Extract date for easier reading
                date_part = start.split('T')[0] if 'T' in start else start
                
                true_duplicates[key] = {
                    'subject': subject,
                    'date': date_part,
                    'start_time': start,
                    'count': len(events),
                    'events': events,
                    'description': f"'{subject}' on {date_part}"
                }
        
        return jsonify({
            "total_events_checked": len(target_events),
            "true_duplicate_groups": len(true_duplicates),
            "true_duplicates": true_duplicates,
            "summary": {
                "total_duplicate_events": sum(dup['count'] for dup in true_duplicates.values()),
                "duplicate_descriptions": [dup['description'] for dup in true_duplicates.values()]
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/clean-precise-duplicates', methods=['POST'])
def clean_precise_duplicates():
    """Remove TRUE duplicates only - keeps legitimate recurring series"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group events by EXACT match criteria
        exact_groups = {}
        
        for event in target_events:
            subject = event.get('subject', '').strip()
            start_datetime = event.get('start', {}).get('dateTime', '')
            end_datetime = event.get('end', {}).get('dateTime', '')
            is_all_day = event.get('isAllDay', False)
            event_type = event.get('type', 'singleInstance')
            
            # Skip recurring series for this cleanup - only handle single events
            if event_type in ['seriesMaster', 'occurrence']:
                continue
                
            # Create precise matching key
            key = f"{subject}|{start_datetime}|{end_datetime}|{is_all_day}"
            
            if key not in exact_groups:
                exact_groups[key] = []
            exact_groups[key].append(event)
        
        # Find true duplicates and keep only the newest
        to_delete = []
        kept_count = 0
        duplicate_groups_found = 0
        
        for key, events in exact_groups.items():
            if len(events) > 1:
                duplicate_groups_found += 1
                
                # Sort by creation time, keep the newest
                events.sort(key=lambda x: x.get('createdDateTime', ''), reverse=True)
                kept_event = events[0]
                duplicates = events[1:]
                
                kept_count += 1
                to_delete.extend(duplicates)
                
                subject = kept_event.get('subject', 'Unknown')
                start = kept_event.get('start', {}).get('dateTime', '')
                date_part = start.split('T')[0] if 'T' in start else start
                
                logger.info(f"Found {len(duplicates)} TRUE duplicates for '{subject}' on {date_part}, keeping newest")
        
        # Delete the true duplicates
        deleted_count = 0
        failed_deletes = []
        
        for event in to_delete:
            event_id = event.get('id')
            subject = event.get('subject', 'Unknown')
            
            if sync_engine.writer.delete_event(target_id, event_id):
                deleted_count += 1
                logger.info(f"Deleted TRUE duplicate: {subject} (ID: {event_id[:8]}...)")
            else:
                failed_deletes.append(event_id)
                logger.error(f"Failed to delete TRUE duplicate: {subject} (ID: {event_id[:8]}...)")
        
        return jsonify({
            "success": True,
            "total_events_found": len(target_events),
            "true_duplicate_groups": duplicate_groups_found,
            "true_duplicates_found": len(to_delete),
            "true_duplicates_deleted": deleted_count,
            "failed_deletes": len(failed_deletes),
            "events_kept": kept_count + len([g for g in exact_groups.values() if len(g) == 1]),
            "failed_delete_ids": failed_deletes,
            "note": "This only removes TRUE duplicates (identical single events), not legitimate recurring series with same names"
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

# Add this BETTER duplicate detector that catches what you see visually

@app.route('/debug/visual-duplicates')
def visual_duplicates():
    """Find ALL duplicates - including recurring event occurrences that show up as visual duplicates"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group by VISUAL appearance - how they look in the calendar
        visual_groups = {}
        
        for event in target_events:
            subject = event.get('subject', '').strip()
            start_datetime = event.get('start', {}).get('dateTime', '')
            
            # Extract date and time for visual grouping
            if 'T' in start_datetime:
                date_part = start_datetime.split('T')[0]  # YYYY-MM-DD
                time_part = start_datetime.split('T')[1][:5]  # HH:MM
                visual_key = f"{subject}|{date_part}|{time_part}"
            else:
                visual_key = f"{subject}|{start_datetime}|no-time"
            
            if visual_key not in visual_groups:
                visual_groups[visual_key] = []
            
            visual_groups[visual_key].append({
                'id': event.get('id'),
                'subject': event.get('subject'),
                'start': start_datetime,
                'type': event.get('type'),
                'created': event.get('createdDateTime'),
                'modified': event.get('lastModifiedDateTime'),
                'series_master_id': event.get('seriesMasterId'),
                'categories': event.get('categories', [])
            })
        
        # Find visual duplicates
        visual_duplicates = {}
        for key, events in visual_groups.items():
            if len(events) > 1:
                # Parse the key for display
                parts = key.split('|')
                subject = parts[0]
                date = parts[1]
                time = parts[2] if len(parts) > 2 else 'no-time'
                
                visual_duplicates[key] = {
                    'subject': subject,
                    'date': date,
                    'time': time,
                    'count': len(events),
                    'events': events,
                    'description': f"'{subject}' on {date} at {time}",
                    'types': [e['type'] for e in events],
                    'series_masters': list(set([e['series_master_id'] for e in events if e['series_master_id']]))
                }
        
        return jsonify({
            "total_events_checked": len(target_events),
            "visual_duplicate_groups": len(visual_duplicates),
            "visual_duplicates": visual_duplicates,
            "summary": {
                "total_duplicate_events": sum(dup['count'] for dup in visual_duplicates.values()),
                "duplicate_descriptions": [dup['description'] for dup in visual_duplicates.values()]
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/clean-visual-duplicates', methods=['POST'])
def clean_visual_duplicates():
    """Remove visual duplicates - keeps one copy of each event that appears multiple times"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({"error": "Could not retrieve target events"}), 500
        
        # Group by visual appearance
        visual_groups = {}
        
        for event in target_events:
            subject = event.get('subject', '').strip()
            start_datetime = event.get('start', {}).get('dateTime', '')
            
            # Create visual key
            if 'T' in start_datetime:
                date_part = start_datetime.split('T')[0]
                time_part = start_datetime.split('T')[1][:5]
                visual_key = f"{subject}|{date_part}|{time_part}"
            else:
                visual_key = f"{subject}|{start_datetime}|no-time"
            
            if visual_key not in visual_groups:
                visual_groups[visual_key] = []
            visual_groups[visual_key].append(event)
        
        # Find duplicates and delete extras
        to_delete = []
        kept_count = 0
        duplicate_groups_found = 0
        
        for key, events in visual_groups.items():
            if len(events) > 1:
                duplicate_groups_found += 1
                
                # Sort by preference: seriesMaster > singleInstance > occurrence
                # Then by creation time (newest first)
                def sort_preference(event):
                    type_priority = {
                        'seriesMaster': 0,
                        'singleInstance': 1, 
                        'occurrence': 2
                    }
                    event_type = event.get('type', 'singleInstance')
                    created = event.get('createdDateTime', '')
                    return (type_priority.get(event_type, 9), created)
                
                events.sort(key=sort_preference, reverse=True)
                kept_event = events[0]
                duplicates = events[1:]
                
                kept_count += 1
                to_delete.extend(duplicates)
                
                # Parse key for logging
                parts = key.split('|')
                subject = parts[0]
                date = parts[1]
                time = parts[2] if len(parts) > 2 else 'no-time'
                
                logger.info(f"Found {len(duplicates)} VISUAL duplicates for '{subject}' on {date} at {time}")
                logger.info(f"  Keeping: {kept_event.get('type')} (ID: {kept_event.get('id', '')[:8]}...)")
                for dup in duplicates:
                    logger.info(f"  Deleting: {dup.get('type')} (ID: {dup.get('id', '')[:8]}...)")
        
        # Delete the visual duplicates
        deleted_count = 0
        failed_deletes = []
        
        for event in to_delete:
            event_id = event.get('id')
            subject = event.get('subject', 'Unknown')
            event_type = event.get('type', 'unknown')
            
            if sync_engine.writer.delete_event(target_id, event_id):
                deleted_count += 1
                logger.info(f"‚úÖ Deleted VISUAL duplicate: {subject} ({event_type}) (ID: {event_id[:8]}...)")
            else:
                failed_deletes.append(event_id)
                logger.error(f"‚ùå Failed to delete VISUAL duplicate: {subject} ({event_type}) (ID: {event_id[:8]}...)")
        
        return jsonify({
            "success": True,
            "total_events_found": len(target_events),
            "visual_duplicate_groups": duplicate_groups_found,
            "visual_duplicates_found": len(to_delete),
            "visual_duplicates_deleted": deleted_count,
            "failed_deletes": len(failed_deletes),
            "events_kept": kept_count + len([g for g in visual_groups.values() if len(g) == 1]),
            "failed_delete_ids": failed_deletes,
            "note": "Removed events that appear identical in calendar view (same subject, date, time)"
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/calendar-view-duplicates')
def calendar_view_duplicates():
    """Check duplicates using calendarView (actual calendar instances)"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        headers = sync_engine.auth.get_headers()
        if not headers:
            return jsonify({"error": "No valid headers"}), 401
        
        # Use calendarView to get actual calendar instances
        import requests
        from datetime import datetime, timedelta
        
        # Get events for next 30 days (including the dates you showed)
        start_date = "2025-06-20T00:00:00.000Z"
        end_date = "2025-07-10T23:59:59.999Z"
        
        url = f"https://graph.microsoft.com/v1.0/users/{config.SHARED_MAILBOX}/calendars/{target_id}/calendarView"
        params = {
            'startDateTime': start_date,
            'endDateTime': end_date,
            '$select': 'id,subject,start,end,type,seriesMasterId,categories,createdDateTime'
        }
        
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        if response.status_code != 200:
            return jsonify({"error": f"API error: {response.status_code}", "details": response.text}), 500
        
        events = response.json().get('value', [])
        
        # Group by visual appearance (subject + start time)
        visual_groups = {}
        
        for event in events:
            subject = event.get('subject', '').strip()
            start_time = event.get('start', {}).get('dateTime', '')
            
            # Create visual key
            visual_key = f"{subject}|{start_time}"
            
            if visual_key not in visual_groups:
                visual_groups[visual_key] = []
            visual_groups[visual_key].append({
                'id': event.get('id'),
                'subject': event.get('subject'),
                'start': start_time,
                'type': event.get('type'),
                'seriesMasterId': event.get('seriesMasterId'),
                'created': event.get('createdDateTime')
            })
        
        # Find duplicates
        duplicates = {}
        for key, events_list in visual_groups.items():
            if len(events_list) > 1:
                parts = key.split('|')
                subject = parts[0]
                start_time = parts[1] if len(parts) > 1 else ''
                
                duplicates[key] = {
                    'subject': subject,
                    'start_time': start_time,
                    'count': len(events_list),
                    'events': events_list
                }
        
        return jsonify({
            "total_calendar_instances": len(events),
            "duplicate_groups": len(duplicates),
            "duplicates": duplicates,
            "summary": {
                "total_duplicate_events": sum(dup['count'] for dup in duplicates.values()),
                "date_range": f"{start_date} to {end_date}"
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

# Add these endpoints to your app.py for better diagnostics

@app.route('/debug/comprehensive-duplicates')
def comprehensive_duplicates():
    """Comprehensive duplicate detection across multiple date ranges"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        headers = sync_engine.auth.get_headers()
        if not headers:
            return jsonify({"error": "No valid headers"}), 401
        
        import requests
        from datetime import datetime, timedelta
        
        # Check multiple approaches
        results = {
            "timestamp": datetime.now().isoformat(),
            "calendar_view_analysis": {},
            "events_analysis": {},
            "date_ranges_checked": []
        }
        
        # Test multiple date ranges
        date_ranges = [
            # Past 30 days
            {
                "name": "past_30_days",
                "start": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%dT00:00:00.000Z"),
                "end": datetime.now().strftime("%Y-%m-%dT23:59:59.999Z")
            },
            # Next 30 days  
            {
                "name": "next_30_days",
                "start": datetime.now().strftime("%Y-%m-%dT00:00:00.000Z"),
                "end": (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%dT23:59:59.999Z")
            },
            # Specific range around June 22-28 (where you saw duplicates)
            {
                "name": "june_focus",
                "start": "2025-06-20T00:00:00.000Z",
                "end": "2025-06-30T23:59:59.999Z"
            }
        ]
        
        for date_range in date_ranges:
            range_name = date_range["name"]
            results["date_ranges_checked"].append(date_range)
            
            # Method 1: CalendarView (actual instances)
            try:
                url = f"https://graph.microsoft.com/v1.0/users/{config.SHARED_MAILBOX}/calendars/{target_id}/calendarView"
                params = {
                    'startDateTime': date_range["start"],
                    'endDateTime': date_range["end"],
                    '$select': 'id,subject,start,end,type,seriesMasterId,categories,createdDateTime,lastModifiedDateTime'
                }
                
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code == 200:
                    calendar_events = response.json().get('value', [])
                    
                    # Analyze for visual duplicates
                    visual_groups = {}
                    for event in calendar_events:
                        subject = event.get('subject', '').strip()
                        start_time = event.get('start', {}).get('dateTime', '')
                        
                        # Extract date and hour for grouping
                        if 'T' in start_time:
                            date_part = start_time.split('T')[0]
                            hour_part = start_time.split('T')[1][:2]  # Just hour
                            visual_key = f"{subject}|{date_part}|{hour_part}"
                        else:
                            visual_key = f"{subject}|{start_time}"
                        
                        if visual_key not in visual_groups:
                            visual_groups[visual_key] = []
                        visual_groups[visual_key].append({
                            'id': event.get('id'),
                            'subject': subject,
                            'start': start_time,
                            'type': event.get('type'),
                            'created': event.get('createdDateTime'),
                            'modified': event.get('lastModifiedDateTime')
                        })
                    
                    # Find duplicates
                    duplicates = {k: v for k, v in visual_groups.items() if len(v) > 1}
                    
                    results["calendar_view_analysis"][range_name] = {
                        "total_instances": len(calendar_events),
                        "duplicate_groups": len(duplicates),
                        "duplicates": duplicates,
                        "all_events": calendar_events[:10]  # First 10 for inspection
                    }
                else:
                    results["calendar_view_analysis"][range_name] = {
                        "error": f"API error: {response.status_code}",
                        "details": response.text[:200]
                    }
            except Exception as e:
                results["calendar_view_analysis"][range_name] = {
                    "error": str(e)
                }
            
            # Method 2: Regular events endpoint (for comparison)
            try:
                url = f"https://graph.microsoft.com/v1.0/users/{config.SHARED_MAILBOX}/calendars/{target_id}/events"
                params = {
                    '$select': 'id,subject,start,end,type,seriesMasterId,categories,createdDateTime,lastModifiedDateTime',
                    '$top': 100
                }
                
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code == 200:
                    logical_events = response.json().get('value', [])
                    
                    results["events_analysis"][range_name] = {
                        "total_events": len(logical_events),
                        "event_types": {},
                        "recurring_events": [],
                        "single_events": []
                    }
                    
                    # Analyze event types
                    type_counts = {}
                    for event in logical_events:
                        event_type = event.get('type', 'unknown')
                        type_counts[event_type] = type_counts.get(event_type, 0) + 1
                        
                        if event_type == 'seriesMaster':
                            results["events_analysis"][range_name]["recurring_events"].append({
                                'subject': event.get('subject'),
                                'id': event.get('id'),
                                'start': event.get('start', {}).get('dateTime'),
                                'recurrence': event.get('recurrence', {}).get('pattern', {}).get('type')
                            })
                        else:
                            results["events_analysis"][range_name]["single_events"].append({
                                'subject': event.get('subject'),
                                'id': event.get('id'),
                                'start': event.get('start', {}).get('dateTime'),
                                'type': event_type
                            })
                    
                    results["events_analysis"][range_name]["event_types"] = type_counts
                else:
                    results["events_analysis"][range_name] = {
                        "error": f"API error: {response.status_code}"
                    }
            except Exception as e:
                results["events_analysis"][range_name] = {
                    "error": str(e)
                }
        
        return jsonify(results)
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/realtime-sync-test', methods=['POST'])
def realtime_sync_test():
    """Trigger a sync and immediately check for duplicates"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        logger.info("üß™ REALTIME SYNC TEST - Before sync analysis")
        
        # 1. Get state before sync
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        before_events = sync_engine.reader.get_calendar_events(target_id)
        before_count = len(before_events) if before_events else 0
        
        # 2. Trigger sync
        logger.info("üîÑ Triggering sync...")
        sync_result = sync_engine.sync_calendars()
        
        # 3. Get state after sync
        after_events = sync_engine.reader.get_calendar_events(target_id)
        after_count = len(after_events) if after_events else 0
        
        # 4. Check for duplicates immediately after sync
        visual_duplicates = {}
        if after_events:
            visual_groups = {}
            for event in after_events:
                subject = event.get('subject', '').strip()
                start_time = event.get('start', {}).get('dateTime', '')
                
                if 'T' in start_time:
                    date_part = start_time.split('T')[0]
                    time_part = start_time.split('T')[1][:5]
                    visual_key = f"{subject}|{date_part}|{time_part}"
                else:
                    visual_key = f"{subject}|{start_time}"
                
                if visual_key not in visual_groups:
                    visual_groups[visual_key] = []
                visual_groups[visual_key].append({
                    'id': event.get('id'),
                    'subject': subject,
                    'start': start_time,
                    'type': event.get('type'),
                    'created': event.get('createdDateTime')
                })
            
            visual_duplicates = {k: v for k, v in visual_groups.items() if len(v) > 1}
        
        return jsonify({
            "sync_result": sync_result,
            "before_sync": {
                "event_count": before_count
            },
            "after_sync": {
                "event_count": after_count,
                "change": after_count - before_count
            },
            "immediate_duplicate_check": {
                "duplicate_groups_found": len(visual_duplicates),
                "duplicates": visual_duplicates
            },
            "analysis": {
                "duplicates_created_by_sync": len(visual_duplicates) > 0,
                "sync_added_events": sync_result.get('added', 0),
                "net_change": after_count - before_count
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

# Add these endpoints to app.py for fresh import testing

@app.route('/debug/wipe-target-calendar', methods=['POST'])
def wipe_target_calendar():
    """DANGER: Completely wipe the target calendar - USE WITH CAUTION"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        # Get confirmation parameter
        confirm = request.json.get('confirm_wipe', '') if request.is_json else request.form.get('confirm_wipe', '')
        if confirm != 'YES_DELETE_ALL_EVENTS':
            return jsonify({
                "error": "Confirmation required",
                "message": "Send POST with JSON: {'confirm_wipe': 'YES_DELETE_ALL_EVENTS'}"
            }), 400
        
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        if not target_id:
            return jsonify({"error": "Target calendar not found"}), 404
        
        # Safety check - make sure we're not wiping the source calendar
        source_id = sync_engine.reader.find_calendar_id(config.SOURCE_CALENDAR)
        if target_id == source_id:
            return jsonify({"error": "SAFETY ABORT: Target and source calendars are the same!"}), 400
        
        logger.info(f"üßπ WIPING TARGET CALENDAR: {config.TARGET_CALENDAR} (ID: {target_id})")
        logger.info("üö® This will delete ALL events in the target calendar!")
        
        # Get all events in target calendar
        target_events = sync_engine.reader.get_calendar_events(target_id)
        if not target_events:
            return jsonify({
                "success": True,
                "message": "Target calendar is already empty",
                "events_deleted": 0
            })
        
        logger.info(f"Found {len(target_events)} events to delete")
        
        # Delete all events
        deleted_count = 0
        failed_deletes = []
        
        for event in target_events:
            event_id = event.get('id')
            subject = event.get('subject', 'Unknown')
            
            try:
                if sync_engine.writer.delete_event(target_id, event_id, suppress_notifications=True):
                    deleted_count += 1
                    logger.info(f"üóëÔ∏è Deleted: {subject} (ID: {event_id[:8]}...)")
                else:
                    failed_deletes.append({
                        'id': event_id,
                        'subject': subject,
                        'error': 'Delete operation failed'
                    })
            except Exception as e:
                failed_deletes.append({
                    'id': event_id,
                    'subject': subject,
                    'error': str(e)
                })
        
        # Verify calendar is empty
        remaining_events = sync_engine.reader.get_calendar_events(target_id)
        remaining_count = len(remaining_events) if remaining_events else 0
        
        logger.info(f"‚úÖ Wipe complete: {deleted_count} deleted, {len(failed_deletes)} failed, {remaining_count} remaining")
        
        return jsonify({
            "success": True,
            "message": f"Target calendar wiped: {deleted_count} events deleted",
            "events_found": len(target_events),
            "events_deleted": deleted_count,
            "failed_deletes": len(failed_deletes),
            "remaining_events": remaining_count,
            "failed_delete_details": failed_deletes,
            "target_calendar": config.TARGET_CALENDAR,
            "target_id": target_id
        })
        
    except Exception as e:
        import traceback
        logger.error(f"üí• Wipe failed: {e}")
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/fresh-import', methods=['POST'])
def fresh_import():
    """Do a fresh import from source to target (assumes target is empty)"""
    try:
        if not sync_engine or not auth_manager or not auth_manager.is_authenticated():
            return jsonify({"error": "Not authenticated"}), 401
        
        logger.info("üöÄ STARTING FRESH IMPORT")
        
        # Get calendar IDs
        source_id = sync_engine.reader.find_calendar_id(config.SOURCE_CALENDAR)
        target_id = sync_engine.reader.find_calendar_id(config.TARGET_CALENDAR)
        
        if not source_id or not target_id:
            return jsonify({"error": "Required calendars not found"}), 404
        
        # Safety check
        if source_id == target_id:
            return jsonify({"error": "SAFETY ABORT: Source and target calendars are identical"}), 400
        
        logger.info(f"üìñ Source: {config.SOURCE_CALENDAR} (ID: {source_id})")
        logger.info(f"üìù Target: {config.TARGET_CALENDAR} (ID: {target_id})")
        
        # Check target is empty (or nearly empty)
        target_events = sync_engine.reader.get_calendar_events(target_id)
        target_count = len(target_events) if target_events else 0
        
        if target_count > 5:
            return jsonify({
                "error": f"Target calendar has {target_count} events. Wipe it first for a true fresh import.",
                "suggestion": "Use /debug/wipe-target-calendar first"
            }), 400
        
        # Get source events
        source_events = sync_engine.reader.get_public_events(source_id)
        if not source_events:
            return jsonify({"error": "No public events found in source calendar"}), 404
        
        logger.info(f"üìä Found {len(source_events)} public events in source")
        
        # Log what we're about to import
        logger.info("üìã EVENTS TO IMPORT:")
        for i, event in enumerate(source_events[:10]):  # Log first 10
            subject = event.get('subject', 'No subject')
            start = event.get('start', {}).get('dateTime', 'No start')
            event_type = event.get('type', 'singleInstance')
            signature = sync_engine._create_event_signature(event)
            logger.info(f"  {i+1}. '{subject}' | {event_type} | Start: {start} | Signature: {signature}")
        
        if len(source_events) > 10:
            logger.info(f"  ... and {len(source_events) - 10} more events")
        
        # Import events one by one (for detailed tracking)
        created_count = 0
        failed_creates = []
        created_signatures = []
        
        for i, event in enumerate(source_events):
            subject = event.get('subject', 'Unknown')
            signature = sync_engine._create_event_signature(event)
            
            # Skip individual occurrences
            if signature.startswith("skip:occurrence:"):
                logger.debug(f"Skipping occurrence: {subject}")
                continue
            
            try:
                logger.info(f"Creating event {i+1}/{len(source_events)}: '{subject}'")
                
                if sync_engine.writer.create_event(target_id, event):
                    created_count += 1
                    created_signatures.append(signature)
                    logger.info(f"‚úÖ Created: {subject}")
                else:
                    failed_creates.append({
                        'subject': subject,
                        'signature': signature,
                        'error': 'Create operation failed'
                    })
                    logger.error(f"‚ùå Failed to create: {subject}")
                    
            except Exception as e:
                failed_creates.append({
                    'subject': subject,
                    'signature': signature,
                    'error': str(e)
                })
                logger.error(f"‚ùå Exception creating {subject}: {e}")
        
        # Check for signature duplicates in what we created
        signature_counts = {}
        for sig in created_signatures:
            signature_counts[sig] = signature_counts.get(sig, 0) + 1
        
        duplicate_signatures = {sig: count for sig, count in signature_counts.items() if count > 1}
        
        # Verify final state
        final_target_events = sync_engine.reader.get_calendar_events(target_id)
        final_count = len(final_target_events) if final_target_events else 0
        
        # Check for visual duplicates in final state
        visual_duplicates = {}
        if final_target_events:
            visual_groups = {}
            for event in final_target_events:
                subject = event.get('subject', '').strip()
                start_time = event.get('start', {}).get('dateTime', '')
                
                if 'T' in start_time:
                    date_part = start_time.split('T')[0]
                    time_part = start_time.split('T')[1][:5]
                    visual_key = f"{subject}|{date_part}|{time_part}"
                else:
                    visual_key = f"{subject}|{start_time}"
                
                if visual_key not in visual_groups:
                    visual_groups[visual_key] = []
                visual_groups[visual_key].append({
                    'id': event.get('id'),
                    'subject': subject,
                    'start': start_time,
                    'type': event.get('type')
                })
            
            visual_duplicates = {k: v for k, v in visual_groups.items() if len(v) > 1}
        
        logger.info(f"üéâ FRESH IMPORT COMPLETE:")
        logger.info(f"  - Source events: {len(source_events)}")
        logger.info(f"  - Events created: {created_count}")
        logger.info(f"  - Failed creates: {len(failed_creates)}")
        logger.info(f"  - Final target count: {final_count}")
        logger.info(f"  - Signature duplicates: {len(duplicate_signatures)}")
        logger.info(f"  - Visual duplicates: {len(visual_duplicates)}")
        
        return jsonify({
            "success": True,
            "message": f"Fresh import complete: {created_count} events created",
            "source_events": len(source_events),
            "events_created": created_count,
            "failed_creates": len(failed_creates),
            "final_target_count": final_count,
            "analysis": {
                "signature_duplicates": duplicate_signatures,
                "visual_duplicates": visual_duplicates,
                "import_efficiency": f"{created_count}/{len(source_events)} events created"
            },
            "failed_create_details": failed_creates,
            "created_signatures": created_signatures[:20]  # First 20 for inspection
        })
        
    except Exception as e:
        import traceback
        logger.error(f"üí• Fresh import failed: {e}")
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/debug/fresh-import-wizard')
def fresh_import_wizard():
    """HTML wizard to guide through fresh import process"""
    return '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Fresh Import Wizard</title>
        <style>
            body { font-family: Arial; padding: 20px; background: #f5f5f5; }
            .card { background: white; padding: 20px; border-radius: 10px; margin: 10px 0; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
            .warning { background: #fff3cd; border-left: 4px solid #ffc107; }
            .danger { background: #f8d7da; border-left: 4px solid #dc3545; }
            .success { background: #d4edda; border-left: 4px solid #28a745; }
            button { padding: 10px 20px; margin: 5px; border: none; border-radius: 5px; cursor: pointer; }
            .btn-danger { background: #dc3545; color: white; }
            .btn-warning { background: #ffc107; color: black; }
            .btn-success { background: #28a745; color: white; }
            .btn-primary { background: #007bff; color: white; }
            #result { margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 5px; max-height: 400px; overflow-y: auto; }
            .step { margin: 15px 0; padding: 15px; border-radius: 5px; }
            .step h3 { margin-top: 0; }
        </style>
    </head>
    <body>
        <h1>üß™ Fresh Import Wizard</h1>
        <p>This wizard will help you completely reset the public calendar and import fresh from the source.</p>
        
        <div class="card danger">
            <h3>‚ö†Ô∏è DANGER ZONE</h3>
            <p><strong>This will delete ALL events in the public calendar!</strong></p>
            <p>Only proceed if you're sure you want to start fresh.</p>
        </div>
        
        <div class="step">
            <h3>Step 1: Check Current State</h3>
            <p>First, let's see what's currently in both calendars.</p>
            <button class="btn-primary" onclick="checkState()">Check Current State</button>
        </div>
        
        <div class="step">
            <h3>Step 2: Wipe Target Calendar</h3>
            <p><strong>‚ö†Ô∏è This will delete ALL events in the public calendar!</strong></p>
            <button class="btn-danger" onclick="wipeCalendar()">WIPE PUBLIC CALENDAR</button>
        </div>
        
        <div class="step">
            <h3>Step 3: Fresh Import</h3>
            <p>Import all public events from source to the now-empty target calendar.</p>
            <button class="btn-success" onclick="freshImport()">DO FRESH IMPORT</button>
        </div>
        
        <div class="step">
            <h3>Step 4: Verify Results</h3>
            <p>Check for any duplicates or issues after the fresh import.</p>
            <button class="btn-primary" onclick="verifyResults()">VERIFY RESULTS</button>
        </div>
        
        <div id="result"></div>
        
        <script>
            function log(message, type = 'info') {
                const result = document.getElementById('result');
                const className = type === 'error' ? 'danger' : type === 'warning' ? 'warning' : type === 'success' ? 'success' : '';
                result.innerHTML += `<div class="card ${className}"><strong>[${new Date().toLocaleTimeString()}]</strong> ${message}</div>`;
                result.scrollTop = result.scrollHeight;
            }
            
            async function checkState() {
                log('üîç Checking current calendar state...', 'info');
                try {
                    const response = await fetch('/status');
                    const data = await response.json();
                    log(`üìä System Status: Authenticated: ${data.authenticated}`, 'info');
                    
                    // Could add more detailed checks here
                    log('‚úÖ Current state checked. Ready for next step.', 'success');
                } catch (error) {
                    log('‚ùå Error checking state: ' + error.message, 'error');
                }
            }
            
            async function wipeCalendar() {
                if (!confirm('üö® Are you ABSOLUTELY SURE you want to delete ALL events in the public calendar?\\n\\nThis action CANNOT be undone!')) {
                    return;
                }
                
                log('üßπ Wiping target calendar... This may take a minute.', 'warning');
                try {
                    const response = await fetch('/debug/wipe-target-calendar', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ confirm_wipe: 'YES_DELETE_ALL_EVENTS' })
                    });
                    
                    const data = await response.json();
                    if (data.success) {
                        log(`‚úÖ Calendar wiped successfully! Deleted ${data.events_deleted} events.`, 'success');
                        if (data.failed_deletes > 0) {
                            log(`‚ö†Ô∏è ${data.failed_deletes} events failed to delete.`, 'warning');
                        }
                    } else {
                        log('‚ùå Wipe failed: ' + (data.error || 'Unknown error'), 'error');
                    }
                } catch (error) {
                    log('‚ùå Wipe error: ' + error.message, 'error');
                }
            }
            
            async function freshImport() {
                log('üöÄ Starting fresh import... This may take a few minutes.', 'info');
                try {
                    const response = await fetch('/debug/fresh-import', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' }
                    });
                    
                    const data = await response.json();
                    if (data.success) {
                        log(`‚úÖ Fresh import complete! Created ${data.events_created} events.`, 'success');
                        log(`üìä Analysis: ${data.events_created}/${data.source_events} events imported`, 'info');
                        
                        if (Object.keys(data.analysis.signature_duplicates).length > 0) {
                            log(`‚ö†Ô∏è Found signature duplicates: ${JSON.stringify(data.analysis.signature_duplicates)}`, 'warning');
                        }
                        
                        if (Object.keys(data.analysis.visual_duplicates).length > 0) {
                            log(`‚ö†Ô∏è Found visual duplicates: ${Object.keys(data.analysis.visual_duplicates).length} groups`, 'warning');
                        } else {
                            log(`‚úÖ No visual duplicates found!`, 'success');
                        }
                        
                        if (data.failed_creates > 0) {
                            log(`‚ö†Ô∏è ${data.failed_creates} events failed to create.`, 'warning');
                        }
                    } else {
                        log('‚ùå Import failed: ' + (data.error || 'Unknown error'), 'error');
                    }
                } catch (error) {
                    log('‚ùå Import error: ' + error.message, 'error');
                }
            }
            
            async function verifyResults() {
                log('üîç Verifying import results...', 'info');
                try {
                    const response = await fetch('/debug/comprehensive-duplicates');
                    const data = await response.json();
                    
                    let totalDuplicates = 0;
                    for (const range in data.calendar_view_analysis) {
                        const analysis = data.calendar_view_analysis[range];
                        if (analysis.duplicate_groups) {
                            totalDuplicates += analysis.duplicate_groups;
                            log(`üìÖ ${range}: Found ${analysis.duplicate_groups} duplicate groups`, 'warning');
                        } else {
                            log(`üìÖ ${range}: No duplicates found`, 'success');
                        }
                    }
                    
                    if (totalDuplicates === 0) {
                        log('üéâ SUCCESS! No duplicates found in any date range!', 'success');
                    } else {
                        log(`‚ö†Ô∏è Found ${totalDuplicates} duplicate groups total. May need cleanup.`, 'warning');
                    }
                    
                } catch (error) {
                    log('‚ùå Verification error: ' + error.message, 'error');
                }
            }
        </script>
    </body>
    </html>
    '''

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    logger.info(f"Starting calendar sync service on port {port}")
    app.run(host='0.0.0.0', port=port)
